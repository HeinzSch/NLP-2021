{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "MO1UjM0sXKU0"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZ_tIcLsXKU1"
      },
      "source": [
        "\n",
        "# Example: ProdLDA with Flax and Haiku\n",
        "\n",
        "In this example, we will follow [1] to implement the ProdLDA topic model from\n",
        "Autoencoding Variational Inference For Topic Models by Akash Srivastava and Charles\n",
        "Sutton [2]. This model returns consistently better topics than vanilla LDA and trains\n",
        "much more quickly. Furthermore, it does not require a custom inference algorithm that\n",
        "relies on complex mathematical derivations. This example also serves as an\n",
        "introduction to Flax and Haiku modules in NumPyro.\n",
        "\n",
        "Note that unlike [1, 2], this implementation uses a Dirichlet prior directly rather\n",
        "than approximating it with a softmax-normal distribution.\n",
        "\n",
        "For the interested reader, a nice extension of this model is the CombinedTM model [3]\n",
        "which utilizes a pre-trained sentence transformer (like https://www.sbert.net/) to\n",
        "generate a better representation of the encoded latent vector.\n",
        "\n",
        "**References:**\n",
        "    1. http://pyro.ai/examples/prodlda.html\n",
        "    2. Akash Srivastava, & Charles Sutton. (2017). Autoencoding Variational Inference\n",
        "       For Topic Models.\n",
        "    3. Federico Bianchi, Silvia Terragni, and Dirk Hovy (2021), \"Pre-training is a Hot\n",
        "       Topic: Contextualized Document Embeddings Improve Topic Coherence\"\n",
        "       (https://arxiv.org/abs/2004.03974)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q numpyro@git+https://github.com/pyro-ppl/numpyro"
      ],
      "metadata": {
        "id": "w6PRs9S2XlUb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flax\n",
        "!pip install dm-haiku"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4k6wUVkyXx02",
        "outputId": "63faf7d6-28ac-4e89-e485-2dba96c49642"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flax in /usr/local/lib/python3.7/dist-packages (0.3.6)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.7/dist-packages (from flax) (0.1.0)\n",
            "Requirement already satisfied: jax>=0.2.21 in /usr/local/lib/python3.7/dist-packages (from flax) (0.2.25)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from flax) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.7/dist-packages (from flax) (1.19.5)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.7/dist-packages (from flax) (1.0.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jax>=0.2.21->flax) (3.10.0.2)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax>=0.2.21->flax) (3.3.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from jax>=0.2.21->flax) (0.12.0)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from jax>=0.2.21->flax) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py->jax>=0.2.21->flax) (1.15.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax) (3.0.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax) (2.8.2)\n",
            "Requirement already satisfied: chex>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from optax->flax) (0.1.0)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.7/dist-packages (from optax->flax) (0.1.71+cuda111)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax->flax) (0.11.2)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax->flax) (0.1.6)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from jaxlib>=0.1.37->optax->flax) (2.0)\n",
            "Requirement already satisfied: dm-haiku in /usr/local/lib/python3.7/dist-packages (0.0.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from dm-haiku) (3.10.0.2)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from dm-haiku) (0.12.0)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from dm-haiku) (0.8.9)\n",
            "Requirement already satisfied: jmp>=0.0.2 in /usr/local/lib/python3.7/dist-packages (from dm-haiku) (0.0.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from dm-haiku) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.7.1->dm-haiku) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JEuySy7Xmjv",
        "outputId": "b91782fa-d675-4a92-9645-50956d391905"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "fRwCfDxFXKU5"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "#from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "import flax.linen as nn\n",
        "import haiku as hk\n",
        "import jax\n",
        "from jax import device_put, random\n",
        "import jax.numpy as jnp\n",
        "\n",
        "import numpyro\n",
        "from numpyro.contrib.module import flax_module, haiku_module\n",
        "import numpyro.distributions as dist\n",
        "from numpyro.infer import SVI, TraceMeanField_ELBO\n",
        "\n",
        "\n",
        "class HaikuEncoder:\n",
        "    def __init__(self, vocab_size, num_topics, hidden, dropout_rate):\n",
        "        self._vocab_size = vocab_size\n",
        "        self._num_topics = num_topics\n",
        "        self._hidden = hidden\n",
        "        self._dropout_rate = dropout_rate\n",
        "\n",
        "    def __call__(self, inputs, is_training):\n",
        "        dropout_rate = self._dropout_rate if is_training else 0.0\n",
        "\n",
        "        h = jax.nn.softplus(hk.Linear(self._hidden)(inputs))\n",
        "        h = jax.nn.softplus(hk.Linear(self._hidden)(h))\n",
        "        h = hk.dropout(hk.next_rng_key(), dropout_rate, h)\n",
        "        h = hk.Linear(self._num_topics)(h)\n",
        "\n",
        "        # NB: here we set `create_scale=False` and `create_offset=False` to reduce\n",
        "        # the number of learning parameters\n",
        "        log_concentration = hk.BatchNorm(\n",
        "            create_scale=False, create_offset=False, decay_rate=0.9\n",
        "        )(h, is_training)\n",
        "        return jnp.exp(log_concentration)\n",
        "\n",
        "\n",
        "class HaikuDecoder:\n",
        "    def __init__(self, vocab_size, dropout_rate):\n",
        "        self._vocab_size = vocab_size\n",
        "        self._dropout_rate = dropout_rate\n",
        "\n",
        "    def __call__(self, inputs, is_training):\n",
        "        dropout_rate = self._dropout_rate if is_training else 0.0\n",
        "        h = hk.dropout(hk.next_rng_key(), dropout_rate, inputs)\n",
        "        h = hk.Linear(self._vocab_size, with_bias=False)(h)\n",
        "        return hk.BatchNorm(create_scale=False, create_offset=False, decay_rate=0.9)(\n",
        "            h, is_training\n",
        "        )\n",
        "\n",
        "\n",
        "class FlaxEncoder(nn.Module):\n",
        "    vocab_size: int\n",
        "    num_topics: int\n",
        "    hidden: int\n",
        "    dropout_rate: float\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, inputs, is_training):\n",
        "        h = nn.softplus(nn.Dense(self.hidden)(inputs))\n",
        "        h = nn.softplus(nn.Dense(self.hidden)(h))\n",
        "        h = nn.Dropout(self.dropout_rate, deterministic=not is_training)(h)\n",
        "        h = nn.Dense(self.num_topics)(h)\n",
        "\n",
        "        log_concentration = nn.BatchNorm(\n",
        "            use_bias=False,\n",
        "            use_scale=False,\n",
        "            momentum=0.9,\n",
        "            use_running_average=not is_training,\n",
        "        )(h)\n",
        "        return jnp.exp(log_concentration)\n",
        "\n",
        "\n",
        "class FlaxDecoder(nn.Module):\n",
        "    vocab_size: int\n",
        "    dropout_rate: float\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, inputs, is_training):\n",
        "        h = nn.Dropout(self.dropout_rate, deterministic=not is_training)(inputs)\n",
        "        h = nn.Dense(self.vocab_size, use_bias=False)(h)\n",
        "        return nn.BatchNorm(\n",
        "            use_bias=False,\n",
        "            use_scale=False,\n",
        "            momentum=0.9,\n",
        "            use_running_average=not is_training,\n",
        "        )(h)\n",
        "\n",
        "\n",
        "def model(docs, hyperparams, is_training=False, nn_framework=\"flax\"):\n",
        "    if nn_framework == \"flax\":\n",
        "        decoder = flax_module(\n",
        "            \"decoder\",\n",
        "            FlaxDecoder(hyperparams[\"vocab_size\"], hyperparams[\"dropout_rate\"]),\n",
        "            input_shape=(1, hyperparams[\"num_topics\"]),\n",
        "            # ensure PRNGKey is made available to dropout layers\n",
        "            apply_rng=[\"dropout\"],\n",
        "            # indicate mutable state due to BatchNorm layers\n",
        "            mutable=[\"batch_stats\"],\n",
        "            # to ensure proper initialisation of BatchNorm we must\n",
        "            # initialise with is_training=True\n",
        "            is_training=True,\n",
        "        )\n",
        "    elif nn_framework == \"haiku\":\n",
        "        decoder = haiku_module(\n",
        "            \"decoder\",\n",
        "            # use `transform_with_state` for BatchNorm\n",
        "            hk.transform_with_state(\n",
        "                HaikuDecoder(hyperparams[\"vocab_size\"], hyperparams[\"dropout_rate\"])\n",
        "            ),\n",
        "            input_shape=(1, hyperparams[\"num_topics\"]),\n",
        "            apply_rng=True,\n",
        "            # to ensure proper initialisation of BatchNorm we must\n",
        "            # initialise with is_training=True\n",
        "            is_training=True,\n",
        "        )\n",
        "    else:\n",
        "        raise ValueError(f\"Invalid choice {nn_framework} for argument nn_framework\")\n",
        "\n",
        "    with numpyro.plate(\n",
        "        \"documents\", docs.shape[0], subsample_size=hyperparams[\"batch_size\"]\n",
        "    ):\n",
        "        batch_docs = numpyro.subsample(docs, event_dim=1)\n",
        "        theta = numpyro.sample(\n",
        "            \"theta\", dist.Dirichlet(jnp.ones(hyperparams[\"num_topics\"]))\n",
        "        )\n",
        "\n",
        "        if nn_framework == \"flax\":\n",
        "            logits = decoder(theta, is_training, rngs={\"dropout\": numpyro.prng_key()})\n",
        "        elif nn_framework == \"haiku\":\n",
        "            logits = decoder(numpyro.prng_key(), theta, is_training)\n",
        "\n",
        "        total_count = batch_docs.sum(-1)\n",
        "        numpyro.sample(\n",
        "            \"obs\", dist.Multinomial(total_count, logits=logits), obs=batch_docs\n",
        "        )\n",
        "\n",
        "\n",
        "def guide(docs, hyperparams, is_training=False, nn_framework=\"flax\"):\n",
        "    if nn_framework == \"flax\":\n",
        "        encoder = flax_module(\n",
        "            \"encoder\",\n",
        "            FlaxEncoder(\n",
        "                hyperparams[\"vocab_size\"],\n",
        "                hyperparams[\"num_topics\"],\n",
        "                hyperparams[\"hidden\"],\n",
        "                hyperparams[\"dropout_rate\"],\n",
        "            ),\n",
        "            input_shape=(1, hyperparams[\"vocab_size\"]),\n",
        "            # ensure PRNGKey is made available to dropout layers\n",
        "            apply_rng=[\"dropout\"],\n",
        "            # indicate mutable state due to BatchNorm layers\n",
        "            mutable=[\"batch_stats\"],\n",
        "            # to ensure proper initialisation of BatchNorm we must\n",
        "            # initialise with is_training=True\n",
        "            is_training=True,\n",
        "        )\n",
        "    elif nn_framework == \"haiku\":\n",
        "        encoder = haiku_module(\n",
        "            \"encoder\",\n",
        "            # use `transform_with_state` for BatchNorm\n",
        "            hk.transform_with_state(\n",
        "                HaikuEncoder(\n",
        "                    hyperparams[\"vocab_size\"],\n",
        "                    hyperparams[\"num_topics\"],\n",
        "                    hyperparams[\"hidden\"],\n",
        "                    hyperparams[\"dropout_rate\"],\n",
        "                )\n",
        "            ),\n",
        "            input_shape=(1, hyperparams[\"vocab_size\"]),\n",
        "            apply_rng=True,\n",
        "            # to ensure proper initialisation of BatchNorm we must\n",
        "            # initialise with is_training=True\n",
        "            is_training=True,\n",
        "        )\n",
        "    else:\n",
        "        raise ValueError(f\"Invalid choice {nn_framework} for argument nn_framework\")\n",
        "\n",
        "    with numpyro.plate(\n",
        "        \"documents\", docs.shape[0], subsample_size=hyperparams[\"batch_size\"]\n",
        "    ):\n",
        "        batch_docs = numpyro.subsample(docs, event_dim=1)\n",
        "\n",
        "        if nn_framework == \"flax\":\n",
        "            concentration = encoder(\n",
        "                batch_docs, is_training, rngs={\"dropout\": numpyro.prng_key()}\n",
        "            )\n",
        "        elif nn_framework == \"haiku\":\n",
        "            concentration = encoder(numpyro.prng_key(), batch_docs, is_training)\n",
        "\n",
        "        numpyro.sample(\"theta\", dist.Dirichlet(concentration))\n",
        "\n",
        "\n",
        "def load_data():\n",
        "    news = pd.read_csv(\"/content/drive/MyDrive/INFO279-2021-LOCAL/NLP-2021-main/data_clean.csv\")\n",
        "    vectorizer = CountVectorizer()\n",
        "    docs = jnp.array(vectorizer.fit_transform(news[\"text\"][:8000]).toarray())\n",
        "\n",
        "    vocab = pd.DataFrame(columns=[\"word\", \"index\"])\n",
        "    vocab[\"word\"] = vectorizer.get_feature_names()\n",
        "    vocab[\"index\"] = vocab.index\n",
        "\n",
        "    \n",
        "    \n",
        "    return docs, vocab\n",
        "\n",
        "\n",
        "def run_inference(docs, args):\n",
        "    rng_key = random.PRNGKey(0)\n",
        "    docs = device_put(docs)\n",
        "\n",
        "    hyperparams = dict(\n",
        "        vocab_size=docs.shape[1],\n",
        "        num_topics=15,\n",
        "        hidden=200,\n",
        "        dropout_rate=0.2,\n",
        "        batch_size=64,\n",
        "    )\n",
        "\n",
        "    optimizer = numpyro.optim.Adam(1e-5)\n",
        "    svi = SVI(model, guide, optimizer, loss=TraceMeanField_ELBO())\n",
        "\n",
        "    return svi.run(\n",
        "        rng_key,\n",
        "        30000,\n",
        "        docs,\n",
        "        hyperparams,\n",
        "        is_training=True,\n",
        "        progress_bar=True,\n",
        "        nn_framework=\"flax\",\n",
        "    )\n",
        "\n",
        "\n",
        "def plot_word_cloud(b, ax, vocab, n):\n",
        "    indices = jnp.argsort(b)[::-1]\n",
        "    top20 = indices[:20]\n",
        "    df = pd.DataFrame(top20, columns=[\"index\"])\n",
        "    words = pd.merge(df, vocab[[\"index\", \"word\"]], how=\"left\", on=\"index\")[\n",
        "        \"word\"\n",
        "    ].values.tolist()\n",
        "    sizes = b[top20].tolist()\n",
        "    freqs = {words[i]: sizes[i] for i in range(len(words))}\n",
        "    wc = WordCloud(background_color=\"white\", width=800, height=500)\n",
        "    wc = wc.generate_from_frequencies(freqs)\n",
        "    ax.set_title(f\"Topic {n + 1}\")\n",
        "    ax.imshow(wc, interpolation=\"bilinear\")\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "\n",
        "def main(args):\n",
        "    docs, vocab = load_data()\n",
        "    print(f\"Dictionary size: {len(vocab)}\")\n",
        "    print(f\"Corpus size: {docs.shape}\")\n",
        "\n",
        "    \n",
        "    \n",
        "    svi_result = run_inference(docs, args)\n",
        "\n",
        "    if args.nn_framework == \"flax\":\n",
        "        beta = svi_result.params[\"decoder$params\"][\"Dense_0\"][\"kernel\"]\n",
        "    elif args.nn_framework == \"haiku\":\n",
        "        beta = svi_result.params[\"decoder$params\"][\"linear\"][\"w\"]\n",
        "\n",
        "    beta = jax.nn.softmax(beta)\n",
        "\n",
        "    # the number of plots depends on the chosen number of topics.\n",
        "    # add 2 to num topics to ensure we create a row for any remainder after division\n",
        "    nrows = (args.num_topics + 2) // 3\n",
        "    fig, axs = plt.subplots(nrows, 3, figsize=(14, 3 + 3 * nrows))\n",
        "    axs = axs.flatten()\n",
        "\n",
        "    for n in range(beta.shape[0]):\n",
        "        plot_word_cloud(beta[n], axs[n], vocab, n)\n",
        "\n",
        "    # hide any unused axes\n",
        "    for i in range(n, len(axs)):\n",
        "        axs[i].axis(\"off\")\n",
        "\n",
        "    fig.savefig(\"wordclouds.png\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install easydict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGDWJeZkeEYZ",
        "outputId": "7b3b7ccc-ae05-4c39-da24-b37ffa97d301"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: easydict in /usr/local/lib/python3.7/dist-packages (1.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "85MNH7fKXKU9",
        "outputId": "e4269a23-499b-446b-db4d-35e741f76bd0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cpu'"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "\"\"\"\n",
        "assert numpyro.__version__.startswith(\"0.8.0\")\n",
        "parser = argparse.ArgumentParser(description=\"Probabilistic topic modelling with Flax and Haiku\")\n",
        "parser.add_argument(\"-n\", \"--num-steps\", nargs=\"?\", default=30000, type=int)\n",
        "parser.add_argument(\"-t\", \"--num-topics\", nargs=\"?\", default=12, type=int)\n",
        "parser.add_argument(\"--batch-size\", nargs=\"?\", default=32, type=int)\n",
        "parser.add_argument(\"--learning-rate\", nargs=\"?\", default=1e-3, type=float)\n",
        "parser.add_argument(\"--hidden\", nargs=\"?\", default=200, type=int)\n",
        "parser.add_argument(\"--dropout-rate\", nargs=\"?\", default=0.2, type=float)\n",
        "parser.add_argument(\n",
        "    \"-dp\",\n",
        "    \"--disable-progbar\",\n",
        "    action=\"store_true\",\n",
        "    default=False,\n",
        "    help=\"Whether to disable progress bar\",\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--device\", default=\"cpu\", type=str, help='use \"cpu\", \"gpu\" or \"tpu\".'\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--nn-framework\",\n",
        "    nargs=\"?\",\n",
        "    default=\"flax\",\n",
        "    help=(\n",
        "        \"The framework to use for constructing encoder / decoder. Options are \"\n",
        "        '\"flax\" or \"haiku\".'\n",
        "    ),\n",
        ")\n",
        "\"\"\"\n",
        "import easydict\n",
        "args = easydict.EasyDict({\n",
        "        \"n\":3000,\n",
        "        \"num-steps\": 3000,\n",
        "        \"t\":15,\n",
        "        \"num-topics\": 15,\n",
        "        \"batch-size\": 32,\n",
        "        \"learning-rate\":1e-3,\n",
        "        \"hidden\": 200,\n",
        "        \"dropout-rate\": 0.2,\n",
        "        \"dp\": False,\n",
        "        \"disable-progbar\":False,\n",
        "        \"device\":\"cpu\",\n",
        "        \"nn-framework\":\"flax\"\n",
        "\n",
        "})\n",
        "args.device"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numpyro.set_platform(args.device)\n",
        "\n",
        "main(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97qdzZKEgjbD",
        "outputId": "7ff3e2db-0f34-4aac-f9ef-b969856518bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dictionary size: 60060\n",
            "Corpus size: (5000, 60060)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|â–Œ         | 1786/30000 [07:03<1:42:47,  4.57it/s, init loss: 12182589.0000, avg. loss [1-1500]: 13556272.0000]"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "name": "prodlda.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}