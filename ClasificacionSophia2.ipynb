{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1.3\n"
     ]
    }
   ],
   "source": [
    "#NLP\n",
    "import spacy\n",
    "nlp = spacy.load(\"es_core_news_lg\")\n",
    "print(spacy.__version__)\n",
    "from spacy.lang.es.stop_words import STOP_WORDS\n",
    "from spacy.lang.es import Spanish\n",
    "import string\n",
    "\n",
    "#SKLEARN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression # Regresion Logística\n",
    "\n",
    "#PANDAS\n",
    "import pandas as pd\n",
    "\n",
    "#NUMPY\n",
    "import numpy as np\n",
    "\n",
    "#PYTORCH\n",
    "import torch\n",
    "import random\n",
    "import torchtext\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "from torchtext.legacy import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparacion entre modelos random forest vs cnn para la clasificacion de topicos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datos/sophia2_data_23112021.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90c0a384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "      <th>Dominant_Topic_Name</th>\n",
       "      <th>Dominant_Topic_REF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.9859</td>\n",
       "      <td>partido, equipo, jugar, jugador, club, chileno...</td>\n",
       "      <td>queda cerca de un mes para que comience el tor...</td>\n",
       "      <td>Deporte</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>región, caso, comuna, salud, sanitario, cuaren...</td>\n",
       "      <td>el gobierno anunció cambios en comunas de todo...</td>\n",
       "      <td>Salud</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.4317</td>\n",
       "      <td>millón, empresa, económico, mes, mercado, dóla...</td>\n",
       "      <td>con un promedio de un 25% de desempleo, latino...</td>\n",
       "      <td>Economia</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.3685</td>\n",
       "      <td>agua, zona, proyecto, vehículo, ambiental, exp...</td>\n",
       "      <td>¿los aficionados al queso pueden seguir disfru...</td>\n",
       "      <td>Ecologia y Planeta</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.9380</td>\n",
       "      <td>vacuna, salud, dosis, vacunación, médico, estu...</td>\n",
       "      <td>el ministerio de salud aseguró este jueves que...</td>\n",
       "      <td>Salud</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50465</th>\n",
       "      <td>50465</td>\n",
       "      <td>50465</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9439</td>\n",
       "      <td>carabinero, encontrar, vehículo, policía, homb...</td>\n",
       "      <td>durante la tarde de este martes, efectivos de ...</td>\n",
       "      <td>Crimen, Delitos y Justicia</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50466</th>\n",
       "      <td>50466</td>\n",
       "      <td>50466</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5740</td>\n",
       "      <td>carabinero, encontrar, vehículo, policía, homb...</td>\n",
       "      <td>el primer tribunal de juicio oral en lo penal ...</td>\n",
       "      <td>Crimen, Delitos y Justicia</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50467</th>\n",
       "      <td>50467</td>\n",
       "      <td>50467</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>región, caso, comuna, salud, sanitario, cuaren...</td>\n",
       "      <td>este viernes las autoridades de salud entregar...</td>\n",
       "      <td>Salud</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50468</th>\n",
       "      <td>50468</td>\n",
       "      <td>50468</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.3845</td>\n",
       "      <td>vacuna, salud, dosis, vacunación, médico, estu...</td>\n",
       "      <td>el ministro de salud,  enrique paris,  reproch...</td>\n",
       "      <td>Salud</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50469</th>\n",
       "      <td>50469</td>\n",
       "      <td>50469</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.2609</td>\n",
       "      <td>región, caso, comuna, salud, sanitario, cuaren...</td>\n",
       "      <td>el diputado y presidente de la federación regi...</td>\n",
       "      <td>Salud</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50470 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  Document_No  Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "0               0            0             6.0              0.9859   \n",
       "1               1            1            14.0              0.9700   \n",
       "2               2            2             5.0              0.4317   \n",
       "3               3            3            10.0              0.3685   \n",
       "4               4            4            15.0              0.9380   \n",
       "...           ...          ...             ...                 ...   \n",
       "50465       50465        50465             1.0              0.9439   \n",
       "50466       50466        50466             1.0              0.5740   \n",
       "50467       50467        50467            14.0              0.9956   \n",
       "50468       50468        50468            15.0              0.3845   \n",
       "50469       50469        50469            14.0              0.2609   \n",
       "\n",
       "                                                Keywords  \\\n",
       "0      partido, equipo, jugar, jugador, club, chileno...   \n",
       "1      región, caso, comuna, salud, sanitario, cuaren...   \n",
       "2      millón, empresa, económico, mes, mercado, dóla...   \n",
       "3      agua, zona, proyecto, vehículo, ambiental, exp...   \n",
       "4      vacuna, salud, dosis, vacunación, médico, estu...   \n",
       "...                                                  ...   \n",
       "50465  carabinero, encontrar, vehículo, policía, homb...   \n",
       "50466  carabinero, encontrar, vehículo, policía, homb...   \n",
       "50467  región, caso, comuna, salud, sanitario, cuaren...   \n",
       "50468  vacuna, salud, dosis, vacunación, médico, estu...   \n",
       "50469  región, caso, comuna, salud, sanitario, cuaren...   \n",
       "\n",
       "                                                    Text  \\\n",
       "0      queda cerca de un mes para que comience el tor...   \n",
       "1      el gobierno anunció cambios en comunas de todo...   \n",
       "2      con un promedio de un 25% de desempleo, latino...   \n",
       "3      ¿los aficionados al queso pueden seguir disfru...   \n",
       "4      el ministerio de salud aseguró este jueves que...   \n",
       "...                                                  ...   \n",
       "50465  durante la tarde de este martes, efectivos de ...   \n",
       "50466  el primer tribunal de juicio oral en lo penal ...   \n",
       "50467  este viernes las autoridades de salud entregar...   \n",
       "50468  el ministro de salud,  enrique paris,  reproch...   \n",
       "50469  el diputado y presidente de la federación regi...   \n",
       "\n",
       "              Dominant_Topic_Name  Dominant_Topic_REF  \n",
       "0                         Deporte                   7  \n",
       "1                           Salud                  10  \n",
       "2                        Economia                   2  \n",
       "3              Ecologia y Planeta                   8  \n",
       "4                           Salud                  10  \n",
       "...                           ...                 ...  \n",
       "50465  Crimen, Delitos y Justicia                   9  \n",
       "50466  Crimen, Delitos y Justicia                   9  \n",
       "50467                       Salud                  10  \n",
       "50468                       Salud                  10  \n",
       "50469                       Salud                  10  \n",
       "\n",
       "[50470 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandasql import sqldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dominant_Topic_Name</th>\n",
       "      <th>count(*)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Salud</td>\n",
       "      <td>10449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crimen, Delitos y Justicia</td>\n",
       "      <td>9354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Politica y Conflictos</td>\n",
       "      <td>8861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cultura y Artes</td>\n",
       "      <td>6567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Deporte</td>\n",
       "      <td>5078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mundo</td>\n",
       "      <td>3287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Economia</td>\n",
       "      <td>2755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ecologia y Planeta</td>\n",
       "      <td>2640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Catastrofes y Accidentes</td>\n",
       "      <td>1479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Dominant_Topic_Name  count(*)\n",
       "0                       Salud     10449\n",
       "1  Crimen, Delitos y Justicia      9354\n",
       "2       Politica y Conflictos      8861\n",
       "3             Cultura y Artes      6567\n",
       "4                     Deporte      5078\n",
       "5                       Mundo      3287\n",
       "6                    Economia      2755\n",
       "7          Ecologia y Planeta      2640\n",
       "8    Catastrofes y Accidentes      1479"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_sql=\"SELECT Dominant_Topic_Name, count(*) FROM df GROUP BY Dominant_Topic_Name ORDER BY count(*) DESC;\"\n",
    "df_result=sqldf(query_sql)\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7615f51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Text'] # the features we want to analyze\n",
    "ylabels = df['Dominant_Topic_Name'] # the labels, or answers, we want to test against\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1b74ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our list of punctuation marks\n",
    "punctuations = [\".\",\",\",\"!\",\"?\", \"#\",\"&\"]\n",
    "\n",
    "# Create our list of stopwords\n",
    "stop_words=[\"\"]\n",
    "\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "parser = Spanish()\n",
    "\n",
    "# Creating our tokenizer function\n",
    "def spacy_tokenizer(sentence):\n",
    "    # Creating our token object, which is used to create documents with linguistic annotations.\n",
    "    mytokens = parser(sentence)\n",
    "\n",
    "    # Lemmatizing each token and converting each token into lowercase\n",
    "    mytokens = [word.lower_ for word in mytokens]\n",
    "        \n",
    "    # Removing stop words\n",
    "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]\n",
    "\n",
    "    # return preprocessed list of tokens\n",
    "    return mytokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca5f634d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(tokenizer=<function spacy_tokenizer at 0x000001FC93166D30>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_vector = CountVectorizer(tokenizer = spacy_tokenizer, ngram_range=(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f97bfa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessing',\n",
       "                 CountVectorizer(tokenizer=<function spacy_tokenizer at 0x000001FC93166D30>)),\n",
       "                ('regression-ML', RandomForestClassifier(random_state=0))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "modelRF = RandomForestClassifier(random_state=0)\n",
    "\n",
    "model3 = Pipeline([('preprocessing', bow_vector),\n",
    "                 ('regression-ML', modelRF)])\n",
    "\n",
    "# model generation\n",
    "model3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d17e731a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Salud' 'Salud' 'Crimen, Delitos y Justicia' ... 'Deporte' 'Deporte'\n",
      " 'Politica y Conflictos']\n",
      "Logistic Regression Accuracy: 0.823585354255825\n"
     ]
    }
   ],
   "source": [
    "# Predicting with a test dataset\n",
    "predicted = model3.predict(X_test)\n",
    "print(predicted)\n",
    "\n",
    "# Model Accuracy\n",
    "print(\"Logistic Regression Accuracy:\", metrics.accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagnosticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2de96cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 157  118    9    0    0    1    1    5   79]\n",
      " [   1 2058    6    4    0    1   10  107   61]\n",
      " [   1   81 1386   56    4    0    9   37   84]\n",
      " [   0    1   12 1216    0    1    1    4    6]\n",
      " [   4   98   74    5  259    6   15   36  189]\n",
      " [   0   68   25    7    2  284   14  115  202]\n",
      " [   0  106   22    2    0    0  538   95   68]\n",
      " [   0   63    4   11    0    2   31 2033  107]\n",
      " [   0   56   20   10    1    3    7   58 2461]]\n",
      "                            precision    recall  f1-score   support\n",
      "\n",
      "  Catastrofes y Accidentes       0.96      0.42      0.59       370\n",
      "Crimen, Delitos y Justicia       0.78      0.92      0.84      2248\n",
      "           Cultura y Artes       0.89      0.84      0.86      1658\n",
      "                   Deporte       0.93      0.98      0.95      1241\n",
      "        Ecologia y Planeta       0.97      0.38      0.54       686\n",
      "                  Economia       0.95      0.40      0.56       717\n",
      "                     Mundo       0.86      0.65      0.74       831\n",
      "     Politica y Conflictos       0.82      0.90      0.86      2251\n",
      "                     Salud       0.76      0.94      0.84      2616\n",
      "\n",
      "                  accuracy                           0.82     12618\n",
      "                 macro avg       0.88      0.71      0.75     12618\n",
      "              weighted avg       0.84      0.82      0.81     12618\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluación del rendimiento del clasificador\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, predicted)\n",
    "print(confusion_matrix)\n",
    "\n",
    "#Print de la matriz de confusión\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field(tokenize=spacy_tokenizer, batch_first = True)\n",
    "CATEGORY = data.LabelField()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid, test, train = np.split(df, [int(.15*len(df)), int(.3*len(df))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [(None, None),(None, None),(None, None),(None, None),(None, None),('body', TEXT),('category', CATEGORY), (None, None)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"datos/sohpia2_train.csv\", encoding=\"UTF-8\",index=False)\n",
    "valid.to_csv(\"datos/sophia2_valid.csv\", encoding=\"UTF-8\",index=False)\n",
    "test.to_csv(\"datos/sophia2_test.csv\", encoding=\"UTF-8\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "train_data, valid_data, test_data = data.TabularDataset.splits(\n",
    "                                        path = '.',\n",
    "                                        train = 'datos/sohpia2_train.csv',\n",
    "                                        validation= 'datos/sophia2_valid.csv',\n",
    "                                        test = 'datos/sophia2_test.csv',\n",
    "                                        format = 'csv',\n",
    "                                        fields = fields,\n",
    "                                        skip_header = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE, \n",
    "    device = device,\n",
    "    sort_key=lambda x:len(x.category),\n",
    "    sort_within_batch=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 50000\n",
    "\n",
    "## TENER VECTORES EN ESPAÑOL\n",
    "vec = torchtext.vocab.Vectors('glove-sbwc.i25.vec.gz', cache='.')\n",
    "TEXT.build_vocab(train_data, vectors=vec, max_size = MAX_VOCAB_SIZE, unk_init = torch.Tensor.normal_)\n",
    "\n",
    "CATEGORY.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(None, {'Salud': 0, 'Crimen, Delitos y Justicia': 1, 'Politica y Conflictos': 2, 'Cultura y Artes': 3, 'Deporte': 4, 'Mundo': 5, 'Ecologia y Planeta': 6, 'Economia': 7, 'Catastrofes y Accidentes': 8})\n"
     ]
    }
   ],
   "source": [
    "print(CATEGORY.vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN1d(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
    "                 dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        \n",
    "        self.convs = nn.ModuleList([\n",
    "                                    nn.Conv1d(in_channels = embedding_dim, \n",
    "                                              out_channels = n_filters, \n",
    "                                              kernel_size = fs)\n",
    "                                    for fs in filter_sizes\n",
    "                                    ])\n",
    "        \n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "                \n",
    "        embedded = embedded.permute(0, 2, 1)\n",
    "        \n",
    "        conved = [F.relu(conv(embedded)) for conv in self.convs]\n",
    "\n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        \n",
    "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
    "        \n",
    "        return self.fc(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 300\n",
    "N_FILTERS = 100\n",
    "FILTER_SIZES = [3]\n",
    "OUTPUT_DIM = len(CATEGORY.vocab)\n",
    "DROPOUT = 0.5\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "model = CNN1d(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OUTPUT_DIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 15,091,609 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(batch.body).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, batch.category)\n",
    "        \n",
    "        acc = categorical_accuracy(predictions, batch.category)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "    max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n",
    "    correct = max_preds.squeeze(1).eq(y)\n",
    "    return correct.sum() / torch.cuda.FloatTensor([y.shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "           \n",
    "            predictions = model(batch.body).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, batch.category)\n",
    "            \n",
    "            acc = categorical_accuracy(predictions, batch.category)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"inicio optimización\")\n",
    "\n",
    "N_EPOCHS = 20\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        nombre = './models/topic-model-sophia2'+'_ep'+str(epoch+1)+'.pt'\n",
    "        torch.save({'epoca': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'Valid_loss': best_valid_loss}, nombre)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.915 | Test Acc: 86.29%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagnosticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1419   33   49   19    3   21   17   24    5]\n",
      " [  33 1240   53   24    3   32   14    4   19]\n",
      " [  41   51 1177   14    5   30   16   11    1]\n",
      " [  23   23   12  845   18   13   18    7    3]\n",
      " [   3    2    0   21  723    0    3    2    0]\n",
      " [  17   23   17   11    1  396    6    3    1]\n",
      " [  18    7    5   15    2    6  301    6    8]\n",
      " [  28   16   25   16    3   14   13  328    1]\n",
      " [  14   23    1    2    2    0   18    1  148]]\n",
      "[89.24528302 87.20112518 87.44427935 87.83783784 95.88859416 83.36842105\n",
      " 81.79347826 73.87387387 70.81339713]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89      1590\n",
      "           1       0.87      0.87      0.87      1422\n",
      "           2       0.88      0.87      0.88      1346\n",
      "           3       0.87      0.88      0.88       962\n",
      "           4       0.95      0.96      0.96       754\n",
      "           5       0.77      0.83      0.80       475\n",
      "           6       0.74      0.82      0.78       368\n",
      "           7       0.85      0.74      0.79       444\n",
      "           8       0.80      0.71      0.75       209\n",
      "\n",
      "    accuracy                           0.87      7570\n",
      "   macro avg       0.85      0.84      0.84      7570\n",
      "weighted avg       0.87      0.87      0.87      7570\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "nb_classes = 9\n",
    "\n",
    "# Initialize the prediction and label lists(tensors)\n",
    "predlist=torch.zeros(0,dtype=torch.long, device='cpu')\n",
    "lbllist=torch.zeros(0,dtype=torch.long, device='cpu')\n",
    "\n",
    "device = 'cpu'\n",
    "model.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, classes) in enumerate(valid_iterator):\n",
    "        inputs = inputs.to(device)\n",
    "        classes = classes.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        # Append batch prediction results\n",
    "        predlist=torch.cat([predlist,preds.view(-1).cpu()])\n",
    "        lbllist=torch.cat([lbllist,classes.view(-1).cpu()])\n",
    "\n",
    "# Confusion matrix\n",
    "conf_mat=confusion_matrix(lbllist.numpy(), predlist.numpy())\n",
    "print(conf_mat)\n",
    "\n",
    "# Per-class accuracy\n",
    "class_accuracy=100*conf_mat.diagonal()/conf_mat.sum(1)\n",
    "print(class_accuracy)\n",
    "\n",
    "# Classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(lbllist.numpy(), predlist.numpy()))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d9bec91c377bd955fe00704ae77ff3c372cebff61826020c1f6a199d4b374cfc"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('nlp': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
